{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36f80bd3",
   "metadata": {},
   "source": [
    "# Fake WhatsApp data generator\n",
    "This notebook can be used to generated fake WhatsApp data that can be used to interact with What's Viz without having to use own data. Except for the number of particpants in a group that follow a pareto distrubtion and the word distribution that follows english vocab distribution, all other data is randomly generated.\n",
    "\n",
    "Structure of the data:\n",
    "\n",
    "````\n",
    "{\n",
    "    \"messages\":{\n",
    "        <message_id>: {\n",
    "            \"chat\": <chat_id>,\n",
    "            \"sent-by\": <contact-id>,\n",
    "            \"message\": <message-content>,\n",
    "            \"id\": <message_id>,\n",
    "            \"timestamp\": \"yyyy-dd-mm hh:mm:ss +time zone\",\n",
    "        },\n",
    "        ...\n",
    "    },\n",
    "    \"contacts\":{\n",
    "        <contact_id>:{\n",
    "            \"status\": <contact status>,\n",
    "            \"registered\": <true: if user in registred in your contacts, ow. false>,\n",
    "            \"name\": <>,\n",
    "            \"avatar\": <contact picture link>,\n",
    "        },\n",
    "        ...\n",
    "    },\n",
    "    \"groups\": {\n",
    "        \"name\": <group name>,\n",
    "        \"topic\": <group description>,\n",
    "        \"participants\": [<contact_id>, <contact_id>, ...],\n",
    "        \"owner_id\": <contact_id>,\n",
    "        \"avatar\": <group picture link>,\n",
    "    }\n",
    "}\n",
    "````\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5182e0b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1523cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv file with two column name, occurences\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data_for_dummy_generator/unigram_freq.csv')\n",
    "df.head()\n",
    "\n",
    "total_word_occurences = df['count'].sum()\n",
    "\n",
    "def sample_word():\n",
    "    word = np.random.choice(df['word'], p=df['count']/total_word_occurences)\n",
    "    return str(word)\n",
    "\n",
    "def sample_sentence(max_length=20):\n",
    "    sentence = \"\"\n",
    "    random = np.random.randint(3, max_length)\n",
    "    for i in range(random):\n",
    "        sentence += sample_word() + \" \"\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4506c6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'women an megaworks '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff4cd8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create json with fake data with abobve structure\n",
    "import random\n",
    "import json\n",
    "\n",
    "data = {\n",
    "    \"messages\": {},\n",
    "    \"contacts\": {},\n",
    "    \"groups\": {}\n",
    "}\n",
    "\n",
    "def generate_contacts(total, num_registred):\n",
    "\n",
    "    # load json with actors data\n",
    "    with open('data_for_dummy_generator/actor_nodes.json') as f:\n",
    "        actors = json.load(f)\n",
    "\n",
    "    # load json with actors data\n",
    "    with open('data_for_dummy_generator/actors_stats.json') as f:\n",
    "        actors_stats = json.load(f)\n",
    "\n",
    "    random.shuffle(actors)\n",
    "\n",
    "    for i in range(total):\n",
    "        actor = actors[i % len(actors)] \n",
    "        actor_stats = actors_stats[actor[\"id\"]]\n",
    "        data[\"contacts\"][f\"0{i}\"] = {\n",
    "            \"status\": sample_sentence(10),\n",
    "            \"registered\": num_registred > i,\n",
    "            \"name\": actor[\"id\"],\n",
    "            \"avatar\": f'https://image.tmdb.org/t/p/w200/{actor_stats[\"profile_path\"]}' if \"profile_path\" in actor_stats else '',\n",
    "        }\n",
    "\n",
    "def generate_groups(total, own_id):\n",
    "\n",
    "    from scipy.stats import pareto\n",
    "\n",
    "    distribution = pareto(1.16, loc=5, scale=1)\n",
    "    num_participants = distribution.rvs(total)\n",
    "\n",
    "    for i in range(total):\n",
    "        participants = list(np.random.choice(list(data[\"contacts\"]), size=int(num_participants[i]), replace=False))\n",
    "        participants.append(own_id)\n",
    "\n",
    "        data[\"groups\"][f\"1{i}\"] = {\n",
    "            \"name\": sample_sentence(5),\n",
    "            \"topic\": sample_sentence(10),\n",
    "            \"participants\": participants,\n",
    "            \"owner_id\": participants[0],\n",
    "            \"avatar\": ''\n",
    "        }\n",
    "\n",
    "def generate_messages(total, own_id):\n",
    "\n",
    "    for i in range(total):\n",
    "        # If group, pick a contact at random\n",
    "        if random.random() < 0.5:\n",
    "            chat_id = random.choice(list(data[\"groups\"].keys()))\n",
    "            sender = random.choice(data[\"groups\"][chat_id][\"participants\"])\n",
    "        # If contact, sender is either the contact or the user\n",
    "        else:\n",
    "            chat_id = random.choice(list(data[\"contacts\"].keys()))\n",
    "            if random.random() < 0.5:\n",
    "                sender = chat_id \n",
    "            else:\n",
    "                sender = own_id\n",
    "\n",
    "    \n",
    "        data[\"messages\"][f\"2{i}\"] = {\n",
    "            \"chat\": chat_id,\n",
    "            \"sent-by\": sender,\n",
    "            \"message\": sample_sentence(20),\n",
    "            \"id\": f\"2{i}\",\n",
    "            \"timestamp\": f\"202{np.random.randint(0,3)}-{np.random.randint(1,29)}-{np.random.randint(1,13)} {np.random.randint(0,23)}:{np.random.randint(0,59)}:{np.random.randint(0,59)} +0200 UTC+2\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dcfa4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done contacts\n",
      "Done groups\n",
      "Done messages\n",
      "Saved file: wa-visualization/public/dummy-data.json\n"
     ]
    }
   ],
   "source": [
    "generate_contacts(200, 200)\n",
    "own_id = random.choice(list(data[\"contacts\"].keys()))\n",
    "print(\"Done contacts\")\n",
    "generate_groups(30, own_id)\n",
    "print(\"Done groups\")\n",
    "# This might take a few minutes depending on the number of messages (~5 minutes for 4000 messages on my machine)\n",
    "generate_messages(4000, own_id)\n",
    "print(\"Done messages\")\n",
    "\n",
    "dummy_data_path = \"wa-visualization/public/dummy-data.json\"\n",
    "\n",
    "# save json\n",
    "with open(dummy_data_path, 'w') as outfile:\n",
    "    json.dump(data, outfile)\n",
    "\n",
    "print(f\"Saved file: {dummy_data_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
